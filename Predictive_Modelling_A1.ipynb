{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve, mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.regression.linear_model import GLS, GLSAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A (25%)\n",
    "1. Download the “dataset_lm.csv” file from Canvas and upload it to Jupyter Notebook.\n",
    "2. Run the OLS model by using the dependent and explanatory variables in the dataset.\n",
    "3. Show your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mikeredshaw/Documents/Schulich MBAN/Predictive Modelling | MBAN 5110 U /Assignment 1/dataset_lm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.293458</td>\n",
       "      <td>13.698667</td>\n",
       "      <td>50.639873</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.568035</td>\n",
       "      <td>45.121911</td>\n",
       "      <td>11.412501</td>\n",
       "      <td>56.410757</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.281132</td>\n",
       "      <td>38.996909</td>\n",
       "      <td>-3.010548</td>\n",
       "      <td>49.195073</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.153143</td>\n",
       "      <td>46.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.473431</td>\n",
       "      <td>2.714725</td>\n",
       "      <td>65.845845</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.105932</td>\n",
       "      <td>47.190213</td>\n",
       "      <td>10.080280</td>\n",
       "      <td>65.383107</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.763585</td>\n",
       "      <td>51.654939</td>\n",
       "      <td>4.991111</td>\n",
       "      <td>45.591729</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.474403</td>\n",
       "      <td>53.383508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.195330</td>\n",
       "      <td>11.618072</td>\n",
       "      <td>65.072497</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.897464</td>\n",
       "      <td>52.163036</td>\n",
       "      <td>11.057301</td>\n",
       "      <td>82.812717</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.733547</td>\n",
       "      <td>48.913837</td>\n",
       "      <td>-2.457696</td>\n",
       "      <td>56.608806</td>\n",
       "      <td>0</td>\n",
       "      <td>-27.903299</td>\n",
       "      <td>48.515026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.074583</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>45.408996</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.316132</td>\n",
       "      <td>54.356714</td>\n",
       "      <td>5.029029</td>\n",
       "      <td>48.812471</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.825591</td>\n",
       "      <td>45.851732</td>\n",
       "      <td>14.974177</td>\n",
       "      <td>47.362594</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.064411</td>\n",
       "      <td>55.266254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.035569</td>\n",
       "      <td>9.077544</td>\n",
       "      <td>73.548021</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.204165</td>\n",
       "      <td>47.186807</td>\n",
       "      <td>12.128134</td>\n",
       "      <td>62.520911</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.804860</td>\n",
       "      <td>47.765904</td>\n",
       "      <td>9.593982</td>\n",
       "      <td>53.700562</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.546302</td>\n",
       "      <td>48.150543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependent Var  Explanatory Var #1  Explanatory Var #2  Explanatory Var #3  \\\n",
       "0      56.293458           13.698667           50.639873                   0   \n",
       "1      58.473431            2.714725           65.845845                   1   \n",
       "2      94.195330           11.618072           65.072497                   0   \n",
       "3      29.074583            0.818623           45.408996                   1   \n",
       "4      86.035569            9.077544           73.548021                   0   \n",
       "\n",
       "   Explanatory Var #4  Explanatory Var #5  Explanatory Var #6  \\\n",
       "0          -18.568035           45.121911           11.412501   \n",
       "1          -25.105932           47.190213           10.080280   \n",
       "2           -7.897464           52.163036           11.057301   \n",
       "3          -18.316132           54.356714            5.029029   \n",
       "4          -19.204165           47.186807           12.128134   \n",
       "\n",
       "   Explanatory Var #7  Explanatory Var #8  Explanatory Var #9  \\\n",
       "0           56.410757                   2          -12.281132   \n",
       "1           65.383107                   3          -36.763585   \n",
       "2           82.812717                   0          -15.733547   \n",
       "3           48.812471                   1          -12.825591   \n",
       "4           62.520911                   2          -13.804860   \n",
       "\n",
       "   Explanatory Var #10  Explanatory Var #11  Explanatory Var #12  \\\n",
       "0            38.996909            -3.010548            49.195073   \n",
       "1            51.654939             4.991111            45.591729   \n",
       "2            48.913837            -2.457696            56.608806   \n",
       "3            45.851732            14.974177            47.362594   \n",
       "4            47.765904             9.593982            53.700562   \n",
       "\n",
       "   Explanatory Var #13  Explanatory Var #14  Explanatory Var #15  \n",
       "0                    0           -21.153143            46.919314  \n",
       "1                    0            -6.474403            53.383508  \n",
       "2                    0           -27.903299            48.515026  \n",
       "3                    1           -10.064411            55.266254  \n",
       "4                    0           -17.546302            48.150543  "
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.838396</td>\n",
       "      <td>7.762058</td>\n",
       "      <td>59.725134</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-16.078411</td>\n",
       "      <td>50.133715</td>\n",
       "      <td>10.420808</td>\n",
       "      <td>61.887309</td>\n",
       "      <td>1.566351</td>\n",
       "      <td>-24.511691</td>\n",
       "      <td>49.728665</td>\n",
       "      <td>7.740874</td>\n",
       "      <td>60.765794</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-16.673762</td>\n",
       "      <td>50.066901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.676960</td>\n",
       "      <td>7.013243</td>\n",
       "      <td>9.579112</td>\n",
       "      <td>0.500593</td>\n",
       "      <td>8.111197</td>\n",
       "      <td>6.975674</td>\n",
       "      <td>11.520725</td>\n",
       "      <td>14.819969</td>\n",
       "      <td>1.115260</td>\n",
       "      <td>8.500500</td>\n",
       "      <td>6.910690</td>\n",
       "      <td>7.102714</td>\n",
       "      <td>9.525835</td>\n",
       "      <td>0.500593</td>\n",
       "      <td>8.106466</td>\n",
       "      <td>6.794584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.997183</td>\n",
       "      <td>-4.832834</td>\n",
       "      <td>44.124858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.774797</td>\n",
       "      <td>30.009511</td>\n",
       "      <td>-9.828552</td>\n",
       "      <td>34.093154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.979696</td>\n",
       "      <td>26.436407</td>\n",
       "      <td>-4.949728</td>\n",
       "      <td>44.158200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.750628</td>\n",
       "      <td>32.118882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.482037</td>\n",
       "      <td>1.720182</td>\n",
       "      <td>51.617692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.792637</td>\n",
       "      <td>45.423422</td>\n",
       "      <td>-0.174835</td>\n",
       "      <td>49.952772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.037707</td>\n",
       "      <td>45.283603</td>\n",
       "      <td>1.838210</td>\n",
       "      <td>52.849792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.797763</td>\n",
       "      <td>45.825931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.780110</td>\n",
       "      <td>7.905455</td>\n",
       "      <td>59.735139</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-15.875481</td>\n",
       "      <td>50.093602</td>\n",
       "      <td>10.422513</td>\n",
       "      <td>62.554591</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-23.767548</td>\n",
       "      <td>49.842746</td>\n",
       "      <td>8.055297</td>\n",
       "      <td>60.773906</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-17.373619</td>\n",
       "      <td>50.038667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>86.801496</td>\n",
       "      <td>13.684104</td>\n",
       "      <td>67.870073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.185191</td>\n",
       "      <td>54.896583</td>\n",
       "      <td>21.059713</td>\n",
       "      <td>74.441216</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-17.419390</td>\n",
       "      <td>54.576381</td>\n",
       "      <td>14.020396</td>\n",
       "      <td>69.262757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.627544</td>\n",
       "      <td>54.962602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.384795</td>\n",
       "      <td>19.973331</td>\n",
       "      <td>76.973576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.060708</td>\n",
       "      <td>70.365951</td>\n",
       "      <td>29.994610</td>\n",
       "      <td>86.895006</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-10.129522</td>\n",
       "      <td>68.201681</td>\n",
       "      <td>19.992891</td>\n",
       "      <td>76.639179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.003168</td>\n",
       "      <td>69.147818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dependent Var  Explanatory Var #1  Explanatory Var #2  \\\n",
       "count     422.000000          422.000000          422.000000   \n",
       "mean       67.838396            7.762058           59.725134   \n",
       "std        25.676960            7.013243            9.579112   \n",
       "min        -2.997183           -4.832834           44.124858   \n",
       "25%        49.482037            1.720182           51.617692   \n",
       "50%        66.780110            7.905455           59.735139   \n",
       "75%        86.801496           13.684104           67.870073   \n",
       "max       133.384795           19.973331           76.973576   \n",
       "\n",
       "       Explanatory Var #3  Explanatory Var #4  Explanatory Var #5  \\\n",
       "count          422.000000          422.000000          422.000000   \n",
       "mean             0.500000          -16.078411           50.133715   \n",
       "std              0.500593            8.111197            6.975674   \n",
       "min              0.000000          -29.774797           30.009511   \n",
       "25%              0.000000          -23.792637           45.423422   \n",
       "50%              0.500000          -15.875481           50.093602   \n",
       "75%              1.000000           -9.185191           54.896583   \n",
       "max              1.000000           -2.060708           70.365951   \n",
       "\n",
       "       Explanatory Var #6  Explanatory Var #7  Explanatory Var #8  \\\n",
       "count          422.000000          422.000000          422.000000   \n",
       "mean            10.420808           61.887309            1.566351   \n",
       "std             11.520725           14.819969            1.115260   \n",
       "min             -9.828552           34.093154            0.000000   \n",
       "25%             -0.174835           49.952772            1.000000   \n",
       "50%             10.422513           62.554591            2.000000   \n",
       "75%             21.059713           74.441216            3.000000   \n",
       "max             29.994610           86.895006            3.000000   \n",
       "\n",
       "       Explanatory Var #9  Explanatory Var #10  Explanatory Var #11  \\\n",
       "count          422.000000           422.000000           422.000000   \n",
       "mean           -24.511691            49.728665             7.740874   \n",
       "std              8.500500             6.910690             7.102714   \n",
       "min            -39.979696            26.436407            -4.949728   \n",
       "25%            -32.037707            45.283603             1.838210   \n",
       "50%            -23.767548            49.842746             8.055297   \n",
       "75%            -17.419390            54.576381            14.020396   \n",
       "max            -10.129522            68.201681            19.992891   \n",
       "\n",
       "       Explanatory Var #12  Explanatory Var #13  Explanatory Var #14  \\\n",
       "count           422.000000           422.000000           422.000000   \n",
       "mean             60.765794             0.500000           -16.673762   \n",
       "std               9.525835             0.500593             8.106466   \n",
       "min              44.158200             0.000000           -29.750628   \n",
       "25%              52.849792             0.000000           -23.797763   \n",
       "50%              60.773906             0.500000           -17.373619   \n",
       "75%              69.262757             1.000000            -9.627544   \n",
       "max              76.639179             1.000000            -2.003168   \n",
       "\n",
       "       Explanatory Var #15  \n",
       "count           422.000000  \n",
       "mean             50.066901  \n",
       "std               6.794584  \n",
       "min              32.118882  \n",
       "25%              45.825931  \n",
       "50%              50.038667  \n",
       "75%              54.962602  \n",
       "max              69.147818  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dependent Var          0\n",
       "Explanatory Var #1     0\n",
       "Explanatory Var #2     0\n",
       "Explanatory Var #3     0\n",
       "Explanatory Var #4     0\n",
       "Explanatory Var #5     0\n",
       "Explanatory Var #6     0\n",
       "Explanatory Var #7     0\n",
       "Explanatory Var #8     0\n",
       "Explanatory Var #9     0\n",
       "Explanatory Var #10    0\n",
       "Explanatory Var #11    0\n",
       "Explanatory Var #12    0\n",
       "Explanatory Var #13    0\n",
       "Explanatory Var #14    0\n",
       "Explanatory Var #15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column names: Index(['Dependent_Var', 'Explanatory_Var_1', 'Explanatory_Var_2',\n",
      "       'Explanatory_Var_3', 'Explanatory_Var_4', 'Explanatory_Var_5',\n",
      "       'Explanatory_Var_6', 'Explanatory_Var_7', 'Explanatory_Var_8',\n",
      "       'Explanatory_Var_9', 'Explanatory_Var_10', 'Explanatory_Var_11',\n",
      "       'Explanatory_Var_12', 'Explanatory_Var_13', 'Explanatory_Var_14',\n",
      "       'Explanatory_Var_15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace('#', '')\n",
    "print(\"New column names:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dependent_Var', 'Explanatory_Var_1', 'Explanatory_Var_2',\n",
       "       'Explanatory_Var_3', 'Explanatory_Var_4', 'Explanatory_Var_5',\n",
       "       'Explanatory_Var_6', 'Explanatory_Var_7', 'Explanatory_Var_8',\n",
       "       'Explanatory_Var_9', 'Explanatory_Var_10', 'Explanatory_Var_11',\n",
       "       'Explanatory_Var_12', 'Explanatory_Var_13', 'Explanatory_Var_14',\n",
       "       'Explanatory_Var_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('Dependent_Var')]\n",
    "y= df['Dependent_Var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory_Var_1     1.307802\n",
      "Explanatory_Var_2     1.766662\n",
      "Explanatory_Var_3     6.608328\n",
      "Explanatory_Var_4     2.072489\n",
      "Explanatory_Var_5    -0.777609\n",
      "Explanatory_Var_6     0.012370\n",
      "Explanatory_Var_7     0.028562\n",
      "Explanatory_Var_8     0.350970\n",
      "Explanatory_Var_9    -0.029347\n",
      "Explanatory_Var_10    0.129243\n",
      "Explanatory_Var_11    0.014474\n",
      "Explanatory_Var_12    0.075209\n",
      "Explanatory_Var_13    0.741353\n",
      "Explanatory_Var_14   -0.021754\n",
      "Explanatory_Var_15    0.121208\n",
      "dtype: float64\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:          Dependent_Var   R-squared (uncentered):                   0.999\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
      "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
      "Date:                Fri, 20 Oct 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        17:45:03   Log-Likelihood:                         -841.76\n",
      "No. Observations:                 422   AIC:                                      1714.\n",
      "Df Residuals:                     407   BIC:                                      1774.\n",
      "Df Model:                          15                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Explanatory_Var_1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
      "Explanatory_Var_2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
      "Explanatory_Var_3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
      "Explanatory_Var_4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
      "Explanatory_Var_5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
      "Explanatory_Var_6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
      "Explanatory_Var_7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
      "Explanatory_Var_8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
      "Explanatory_Var_9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
      "Explanatory_Var_10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
      "Explanatory_Var_11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
      "Explanatory_Var_12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
      "Explanatory_Var_13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
      "Explanatory_Var_14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
      "Explanatory_Var_15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
      "==============================================================================\n",
      "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
      "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
      "Skew:                          -0.004   Prob(JB):                        0.910\n",
      "Kurtosis:                       2.897   Cond. No.                         287.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "print(results.params)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B (25%)\n",
    "1. Use error values from the OLS model to calculate their standard deviation and\n",
    "autocorrelation values for the first three lags.\n",
    "2. Then, run the GLS model accordingly.\n",
    "3. Show your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_values = y - results.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of error values: 1.7757282184664038\n"
     ]
    }
   ],
   "source": [
    "std_error = np.std(error_values)\n",
    "print(f'Standard deviation of error values: {std_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation at lag 1: 0.050656640908617816\n",
      "Autocorrelation at lag 2: 0.05487850922557077\n",
      "Autocorrelation at lag 3: 0.0321011108491575\n"
     ]
    }
   ],
   "source": [
    "autocorr_values = acf(error_values, nlags=3)\n",
    "\n",
    "print(f'Autocorrelation at lag 1: {autocorr_values[1]}')\n",
    "print(f'Autocorrelation at lag 2: {autocorr_values[2]}')\n",
    "print(f'Autocorrelation at lag 3: {autocorr_values[3]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 GLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:          Dependent_Var   R-squared (uncentered):                   0.999\n",
      "Model:                            GLS   Adj. R-squared (uncentered):              0.999\n",
      "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
      "Date:                Fri, 20 Oct 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        17:45:03   Log-Likelihood:                         -841.76\n",
      "No. Observations:                 422   AIC:                                      1714.\n",
      "Df Residuals:                     407   BIC:                                      1774.\n",
      "Df Model:                          15                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Explanatory_Var_1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
      "Explanatory_Var_2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
      "Explanatory_Var_3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
      "Explanatory_Var_4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
      "Explanatory_Var_5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
      "Explanatory_Var_6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
      "Explanatory_Var_7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
      "Explanatory_Var_8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
      "Explanatory_Var_9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
      "Explanatory_Var_10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
      "Explanatory_Var_11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
      "Explanatory_Var_12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
      "Explanatory_Var_13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
      "Explanatory_Var_14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
      "Explanatory_Var_15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
      "==============================================================================\n",
      "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
      "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
      "Skew:                          -0.004   Prob(JB):                        0.910\n",
      "Kurtosis:                       2.897   Cond. No.                         287.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "gls_model = GLS(y, X)\n",
    "gls_results = gls_model.fit()\n",
    "print(gls_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                GLSAR Regression Results                               \n",
      "=======================================================================================\n",
      "Dep. Variable:          Dependent_Var   R-squared (uncentered):                   0.999\n",
      "Model:                          GLSAR   Adj. R-squared (uncentered):              0.999\n",
      "Method:                 Least Squares   F-statistic:                          4.529e+04\n",
      "Date:                Fri, 20 Oct 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        17:45:03   Log-Likelihood:                         -833.33\n",
      "No. Observations:                 419   AIC:                                      1697.\n",
      "Df Residuals:                     404   BIC:                                      1757.\n",
      "Df Model:                          15                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Explanatory_Var_1      1.3060      0.013    102.366      0.000       1.281       1.331\n",
      "Explanatory_Var_2      1.7667      0.009    204.054      0.000       1.750       1.784\n",
      "Explanatory_Var_3      6.6299      0.177     37.437      0.000       6.282       6.978\n",
      "Explanatory_Var_4      2.0728      0.011    190.431      0.000       2.051       2.094\n",
      "Explanatory_Var_5     -0.7781      0.011    -68.785      0.000      -0.800      -0.756\n",
      "Explanatory_Var_6      0.0121      0.008      1.573      0.116      -0.003       0.027\n",
      "Explanatory_Var_7      0.0282      0.006      4.832      0.000       0.017       0.040\n",
      "Explanatory_Var_8      0.3503      0.080      4.394      0.000       0.194       0.507\n",
      "Explanatory_Var_9     -0.0310      0.010     -3.001      0.003      -0.051      -0.011\n",
      "Explanatory_Var_10     0.1297      0.011     11.516      0.000       0.108       0.152\n",
      "Explanatory_Var_11     0.0169      0.013      1.345      0.179      -0.008       0.042\n",
      "Explanatory_Var_12     0.0756      0.009      8.762      0.000       0.059       0.093\n",
      "Explanatory_Var_13     0.7607      0.176      4.319      0.000       0.414       1.107\n",
      "Explanatory_Var_14    -0.0203      0.011     -1.845      0.066      -0.042       0.001\n",
      "Explanatory_Var_15     0.1203      0.012     10.293      0.000       0.097       0.143\n",
      "==============================================================================\n",
      "Omnibus:                        0.340   Durbin-Watson:                   1.887\n",
      "Prob(Omnibus):                  0.844   Jarque-Bera (JB):                0.461\n",
      "Skew:                          -0.033   Prob(JB):                        0.794\n",
      "Kurtosis:                       2.852   Cond. No.                         286.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "glsar_model = GLSAR(y, X, rho=3)\n",
    "glsar_results = glsar_model.fit()\n",
    "print(glsar_results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part C (25%)\n",
    "1. Split the dataset into two as the training and test sets (test size = 0.5).\n",
    "2. Run the Lasso model with alpha=1 and estimate the coefficients using the training set.\n",
    "3. Then, calculate the mean absolute percentage error using the test set.\n",
    "4. Find an approximate value for alpha that minimizes the mean absolute percentage error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Lasso(alpha=1.0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 2.053870361030066\n"
     ]
    }
   ],
   "source": [
    "clf = Lasso(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "lasso_pred = clf.predict(X_test)\n",
    "mse= np.sqrt(mean_squared_error(lasso_pred, y_test))\n",
    "print(f\"Mean Squared Error = {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01 - Mean Squared Error: 0.02054157825367784\n",
      "Alpha: 0.05 - Mean Squared Error: 0.10270080890504057\n",
      "Alpha: 0.1 - Mean Squared Error: 0.20539162259647425\n",
      "Alpha: 0.3 - Mean Squared Error: 0.6161640038844034\n",
      "Alpha: 0.6 - Mean Squared Error: 1.2323237531210687\n",
      "Alpha: 0.8 - Mean Squared Error: 1.6430969428657167\n",
      "Alpha: 1.0 - Mean Squared Error: 2.053870361030066\n",
      "Alpha: 10.0 - Mean Squared Error: 4.217191160231453\n",
      "Alpha: 100.0 - Mean Squared Error: 20.76771757372561\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.01, 0.05, 0.1, 0.3, 0.6, 0.8, 1.0, 10.0, 100.0]\n",
    "mse_values = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    clf = Lasso(alpha=alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    lasso_pred = clf.predict(X_test)\n",
    "\n",
    "    mse = np.sqrt(mean_squared_error(lasso_pred, y_test))\n",
    "    mse_values.append(mse)\n",
    "\n",
    "    print(f\"Alpha: {alpha} - Mean Squared Error: {mse}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
